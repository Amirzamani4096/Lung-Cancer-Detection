{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46c78cc7-d216-4b10-9464-2b43559d666e",
   "metadata": {},
   "source": [
    "**Anchor Box Generation:** In this code, we generate a list of anchor boxes to be used for training the Region Proposal Network (RPN) on CT images, with VGG16 as the backbone. Anchors are a set of predefined bounding boxes at different scales and aspect ratios that serve as reference points for the RPN to predict object locations. Here, the image is divided into a grid, with anchor box centers placed at regular intervals (using a stride of 8 pixels). For each center, multiple anchor boxes with different sizes are generated to capture nodules of varying dimensions. This comprehensive list of anchors helps the RPN learn to propose regions that likely contain lung nodules, which are critical for accurate detection and classification in our lung cancer detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a4106e-6615-4763-9c36-2db2582a7a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "def to_VOC_format(width, height, center_x, center_y):\n",
    "    \"\"\"\n",
    "    Convert center coordinates format to VOC format (min-max coordinates)\n",
    "    \n",
    "    Parameters:\n",
    "    - width (float): The width of the bounding box\n",
    "    - height (float): The height of the bounding box\n",
    "    - center_x (float): The x-coordinate of the center of the bounding box\n",
    "    - center_y (float): The y-coordinate of the center of the bounding box\n",
    "    \n",
    "    Returns:\n",
    "    - x_min (float): The minimum x-coordinate of the bounding box\n",
    "    - y_min (float): The minimum y-coordinate of the bounding box\n",
    "    - x_max (float): The maximum x-coordinate of the bounding box\n",
    "    - y_max (float): The maximum y-coordinate of the bounding box\n",
    "    \"\"\"\n",
    "    x_min = center_x - 0.5 * width\n",
    "    y_min = center_y - 0.5 * height\n",
    "    x_max = center_x + 0.5 * width\n",
    "    y_max = center_y + 0.5 * height\n",
    "    return x_min, y_min, x_max, y_max\n",
    "# Set stride and image dimensions\n",
    "stride = 8\n",
    "w = h = 800 # Assuming square images with 800x800 pixels\n",
    "\n",
    "# Calculate anchor centers at every stride interval\n",
    "x_center = np.arange(3, w, stride) # X-coordinates for anchor centers\n",
    "y_center = np.arange(3, h, stride) # Y-coordinates for anchor centers\n",
    "        \n",
    "# Generate all ordered pairs of x and y ceters\n",
    "center_list = np.array(np.meshgrid(x_center, y_center,  sparse=False, indexing='xy')).T.reshape(-1,2)\n",
    "    ##########################################################    \n",
    "# Define anchor box sizes (width, height)       \n",
    "anchor_shape = [(8,8),(25,25),(38,38),(58,58),(85,85),(120,120)]\n",
    "n_anchors = len(center_list) * len(anchor_shape) # Total number of anchors\n",
    "        \n",
    "# Initialize an array to store anchor boxes\n",
    "anchor_list = np.zeros(shape= (n_anchors, 4))\n",
    "\n",
    "# Generate anchor boxes for each center and each anchor size      \n",
    "count = 0\n",
    "for center in center_list:\n",
    "         center_x, center_y = center[0], center[1]\n",
    "         # Create anchors for each shape\n",
    "         for w,h in anchor_shape:\n",
    "             anchor_xmin,anchor_ymin,anchor_xmax,anchor_ymax = to_VOC_format(w, h, center_x, center_y)\n",
    "             # Store the anchor coordinates\n",
    "             anchor_list[count] = [anchor_xmin, anchor_ymin, anchor_xmax, anchor_ymax]\n",
    "             count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc4eb7c-fadd-4ff7-aee2-f5fb8ef0cd24",
   "metadata": {},
   "source": [
    "**Data Preparation and Target Labeling:** This code prepares the input data and target labels for training a Region Proposal Network (RPN) used in nodule detection tasks. The process involves loading lung nodule data from an Excel file, processing DICOM images to create RGB images, and generating bounding boxes for lung nodules. The code then selects anchors within the image boundaries, computes the Generalized Intersection over Union (GIOU) between ground truth boxes and anchors, and assigns labels to these anchors. These labels indicate whether an anchor is a positive, negative, or neutral example for the RPN. Additionally, the code calculates regression targets (offsets) for the bounding boxes to refine the predictions. The processed images, along with the computed offsets and labels, are stored for use in training the RPN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3915ea-bcb1-4df6-8267-35359def0206",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def GIOU(box1, box2):\n",
    "    \"\"\"\n",
    "    Compute the Generalized Intersection over Union (GIOU) between box1 and box2.\n",
    "    This function measures the overlap between two bounding boxes and adjusts the IOU\n",
    "    by considering the smallest enclosing box that contains both.\n",
    "    \"\"\"\n",
    "    # Calculate coordinates of the overlapping region\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    if (x1 < x2 and y1 < y2):  # Check if there's any overlap\n",
    "        width_overlap = (x2 - x1)\n",
    "        height_overlap = (y2 - y1)\n",
    "        area_overlap = width_overlap * height_overlap\n",
    "    else:\n",
    "        iou = 0\n",
    "        area_overlap = 0\n",
    "\n",
    "    # Calculate the area of both boxes and their union\n",
    "    width_box1 = (box1[2] - box1[0])\n",
    "    height_box1 = (box1[3] - box1[1])\n",
    "    width_box2 = (box2[2] - box2[0])\n",
    "    height_box2 = (box2[3] - box2[1])\n",
    "    area_box1 = width_box1 * height_box1\n",
    "    area_box2 = width_box2 * height_box2\n",
    "    area_union = area_box1 + area_box2 - area_overlap\n",
    "\n",
    "    # Compute IOU\n",
    "    iou = area_overlap / area_union\n",
    "\n",
    "    # Calculate coordinates of the smallest enclosing box\n",
    "    x1 = min(box1[0], box2[0])\n",
    "    y1 = min(box1[1], box2[1])\n",
    "    x2 = max(box1[2], box2[2])\n",
    "    y2 = max(box1[3], box2[3])\n",
    "    enclosing_box_area = (x2 - x1) * (y2 - y1)\n",
    "\n",
    "    # Compute GIOU\n",
    "    giou = iou - (enclosing_box_area - area_union) / enclosing_box_area\n",
    "\n",
    "    return giou\n",
    "\n",
    "def to_center_format(xmin_list, ymin_list, xmax_list, ymax_list):\n",
    "    \"\"\"\n",
    "    Convert bounding box coordinates from (xmin, ymin, xmax, ymax) format to\n",
    "    (x_center, y_center, width, height) format.\n",
    "    \"\"\"\n",
    "    height = ymax_list - ymin_list\n",
    "    width = xmax_list - xmin_list\n",
    "    \n",
    "    center_x = xmin_list + 0.5 * width\n",
    "    center_y = ymin_list + 0.5 * height\n",
    "    \n",
    "    return width, height, center_x, center_y\n",
    "\n",
    "# Load the dataset containing lung nodule information\n",
    "df = pd.read_excel('lung_nodule_data.xlsx')\n",
    "\n",
    "# Initialize an array to store relevant information from the dataset\n",
    "# The columns represent: [constant_0, z-position, diameter, y-position, x-position]\n",
    "u = np.zeros((len(df), 5))\n",
    "u[:,0] = 0\n",
    "u[:,1] = df['z-pos']\n",
    "u[:,2] = df['dia']\n",
    "u[:,3] = df['y-pos']\n",
    "u[:,4] = df['x-pos']\n",
    "\n",
    "# Set up variables for image dimensions and the number of images to process\n",
    "ww = 800  # Image width and height (800x800 pixels)\n",
    "\n",
    "################################################\n",
    "num_image = 422  # Number of images to process  #\n",
    "################################################\n",
    "\n",
    "nn_anch = np.int32((ww / stride) ** 2 * 6)  # Number of anchors per image\n",
    "\n",
    "# Initialize arrays for storing image data, offsets, labels, and bounding boxes\n",
    "image_data = np.zeros((num_image, 800, 800, 3))\n",
    "offset_list_label_list1 = np.zeros((num_image, nn_anch, 5))\n",
    "label_list1 = np.zeros((num_image, nn_anch, 1))\n",
    "bbox_list1 = np.zeros((num_image, 4))\n",
    "\n",
    "# Loop through each image to create input data and target labels for RPN training\n",
    "kk = 0\n",
    "for i in range(num_image):\n",
    "    # Read the DICOM images (3 slices) for the current image set\n",
    "    image1 = 'Dataset/%d-l.dcm' % (i+1)\n",
    "    image2 = 'Dataset/%d-o.dcm' % (i+1)\n",
    "    image3 = 'Dataset/%d-u.dcm' % (i+1)\n",
    "    \n",
    "    images1 = pydicom.read_file(image1)\n",
    "    img_data1 = images1.pixel_array\n",
    "\n",
    "    images2 = pydicom.read_file(image2)\n",
    "    img_data2 = images2.pixel_array\n",
    "\n",
    "    images3 = pydicom.read_file(image3)\n",
    "    img_data3 = images3.pixel_array\n",
    "\n",
    "    # Combine the three slices into one RGB image\n",
    "    img = np.zeros((512, 512, 3))\n",
    "    img[:, :, 0] = img_data1\n",
    "    img[:, :, 1] = img_data2\n",
    "    img[:, :, 2] = img_data3\n",
    "\n",
    "    # Resize the image to 800x800 pixels\n",
    "    img = cv2.resize(img, dsize=(ww, ww), interpolation=cv2.INTER_CUBIC)\n",
    "    image_data[kk, :, :, :] = img\n",
    "    \n",
    "    # Convert the ground truth bounding box coordinates from center format to VOC format\n",
    "    x_min, y_min, x_max, y_max = to_VOC_format(u[i, 2], u[i, 2], u[i, 3], u[i, 4])\n",
    "    bbox_list = np.int32(np.array([x_min, y_min, x_max, y_max]))\n",
    "\n",
    "    # Adjust the bounding box dimensions based on the resizing factor\n",
    "    alter = 800 / 512\n",
    "    bbox_list = bbox_list * alter\n",
    "    bbox_list1[kk, :] = bbox_list\n",
    "    n_object = len([bbox_list])\n",
    "\n",
    "    # Select anchor boxes that are within the image bounds\n",
    "    inside_anchor_idx_list = np.where(\n",
    "        (anchor_list[:, 0] >= 0) &\n",
    "        (anchor_list[:, 1] >= 0) &\n",
    "        (anchor_list[:, 2] <= ww) &\n",
    "        (anchor_list[:, 3] <= ww)\n",
    "    )[0]\n",
    "    \n",
    "    inside_anchor_list = anchor_list[inside_anchor_idx_list]\n",
    "    n_inside_anchor = len(inside_anchor_idx_list)\n",
    "    \n",
    "    # Calculate the GIOU between the ground truth boxes and the selected anchor boxes\n",
    "    iou_list = np.zeros((n_inside_anchor, n_object))\n",
    "    for gt_idx, gt_box in enumerate([bbox_list]):\n",
    "        for anchor_idx, anchor_box in enumerate(inside_anchor_list):\n",
    "            iou_list[anchor_idx] = GIOU(gt_box, anchor_box)  # Using GIOU instead of regular IOU\n",
    "    \n",
    "    # Assign labels to the anchors based on IoU values\n",
    "    data = {\"anchor_id\": inside_anchor_idx_list}\n",
    "    data.update({f\"object_{idx}_iou\": iou_list[:, idx] for idx in range(n_object)})\n",
    "    data[\"max_iou\"] = iou_list.max(axis=1)\n",
    "    data[\"best_gt\"] = iou_list.argmax(axis=1)\n",
    "    \n",
    "    df_iou = pd.DataFrame(data)\n",
    "    \n",
    "    # Identify the anchors with the highest IoU for each ground truth box\n",
    "    best_ious = df_iou.drop([\"anchor_id\", \"max_iou\", \"best_gt\"], axis=1).max().values\n",
    "    best_anchors = df_iou.drop([\"anchor_id\", \"max_iou\", \"best_gt\"], axis=1).values.argmax(axis=0)\n",
    "    top_anchors = np.where(iou_list == best_ious)[0]\n",
    "\n",
    "    # Label the anchors as positive, negative, or neutral\n",
    "    label_column = np.zeros(df_iou.shape[0], dtype=np.int16)\n",
    "    label_column.fill(-1)\n",
    "    label_column[top_anchors] = 1\n",
    "    label_column[np.where(df_iou.max_iou.values >= -0.5)[0]] = 1\n",
    "    label_column[np.where(df_iou.max_iou.values < -0.7)[0]] = 0\n",
    "    df_iou[\"label\"] = label_column\n",
    "\n",
    "    # Calculate the regression targets for the RPN\n",
    "    inside_anchor_width, inside_anchor_height, inside_anchor_center_x, inside_anchor_center_y = to_center_format(\n",
    "        inside_anchor_list[:, 0], \n",
    "        inside_anchor_list[:, 1],\n",
    "        inside_anchor_list[:, 2],\n",
    "        inside_anchor_list[:, 3]\n",
    "    )\n",
    "    \n",
    "    gt_coordinates = np.zeros(np.shape(inside_anchor_list))\n",
    "    for j in range(len(gt_coordinates)):\n",
    "        gt_coordinates[j, :] = bbox_list\n",
    "    \n",
    "    base_width, base_height, base_center_x, base_center_y = to_center_format(\n",
    "        gt_coordinates[:, 0], \n",
    "        gt_coordinates[:, 1],\n",
    "        gt_coordinates[:, 2],\n",
    "        gt_coordinates[:, 3]\n",
    "    )\n",
    "    \n",
    "    # Prevent division by zero\n",
    "    eps = np.finfo(inside_anchor_width.dtype).eps\n",
    "    inside_anchor_height = np.maximum(inside_anchor_height, eps)\n",
    "    inside_anchor_width = np.maximum(inside_anchor_width, eps)\n",
    "    \n",
    "    # Compute the offsets for the RPN regression task\n",
    "    dx = (base_center_x - inside_anchor_center_x) / inside_anchor_width\n",
    "    dy = (base_center_y - inside_anchor_center_y) / inside_anchor_height\n",
    "    dw = np.log(base_width / inside_anchor_width)\n",
    "    dh = np.log(base_height / inside_anchor_height)\n",
    "    \n",
    "    # Add the offsets to the IoU dataframe\n",
    "    df_iou[\"dx\"] = dx\n",
    "    df_iou[\"dy\"] = dy\n",
    "    df_iou[\"dw\"] = dw\n",
    "    df_iou[\"dh\"] = dh\n",
    "\n",
    "    # Create arrays to hold the labels and offsets for all anchors\n",
    "    label_list = np.empty(n_anchors, dtype=np.float32)\n",
    "    label_list.fill(-1)\n",
    "    label_list[df_iou.anchor_id.values] = df_iou.label.values\n",
    "    label_list = np.expand_dims(label_list, 0)\n",
    "    label_list = np.expand_dims(label_list, -1)\n",
    "\n",
    "    offset_list = np.empty(shape=anchor_list.shape, dtype=np.float32)\n",
    "    offset_list.fill(0)\n",
    "    offset_list[df_iou.anchor_id.values] = df_iou[[\"dx\", \"dy\", \"dw\", \"dh\"]].values\n",
    "    offset_list = np.expand_dims(offset_list, 0)\n",
    "\n",
    "    # Combine the offsets and labels into one array\n",
    "    offset_list_label_list = np.column_stack((offset_list[0], label_list[0]))[np.newaxis, :]\n",
    "\n",
    "    # Store the results for this image\n",
    "    offset_list_label_list1[kk, :, :] = offset_list_label_list\n",
    "    label_list1[kk, :, :] = label_list\n",
    "    kk += 1\n",
    "    print(i)\n",
    "\n",
    "# Print the shapes of the resulting arrays\n",
    "print(image_data.shape)\n",
    "print(offset_list_label_list1.shape)\n",
    "print(label_list1.shape)\n",
    "\n",
    "data = {'images': image_data,'reg':offset_list_label_list1,'clc':label_list1,'GT':bbox_list1, 'annotaton':u}\n",
    "with open('data.pkl', 'wb') as file:\n",
    "    pickle.dump(data, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b570c-d0f6-48f9-b2ed-9f2f9fb7213e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
