{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e71ee623-fca3-48e0-aa07-f57112ec6bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "\n",
    "with open('data.pkl', 'rb') as f:\n",
    "   Data = pickle.load(f)\n",
    "    \n",
    "bbox_list1 = Data['GT']\n",
    "u = Data['annotaton']\n",
    "\n",
    "image_data1 = np.transpose(Data['images'], (0, 3, 1, 2))\n",
    "images = torch.tensor(image_data1)\n",
    "images = images.to(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a638574b-d5a5-4262-a5a7-1b4b9a761e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOU(box1, box2):\n",
    "    \"\"\"\n",
    "    Compute overlap (IOU) between box1 and box2\n",
    "    \"\"\"\n",
    "\n",
    "    # ------calculate coordinate of overlapping region------\n",
    "    # take max of x1 and y1 out of both boxes\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "\n",
    "    # take min of x2 and y2 out of both boxes\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    # check if they atleast overlap a little\n",
    "    if (x1 < x2 and y1 < y2):\n",
    "        # ------area of overlapping region------\n",
    "        width_overlap = (x2 - x1)\n",
    "        height_overlap = (y2 - y1)\n",
    "        area_overlap = width_overlap * height_overlap\n",
    "    else:\n",
    "        # there is no overlap\n",
    "        return 0\n",
    "\n",
    "    # ------computing union------\n",
    "    # sum of area of both the boxes - area_overlap\n",
    "\n",
    "    # height and width of both boxes\n",
    "    width_box1 = (box1[2] - box1[0])\n",
    "    height_box1 = (box1[3] - box1[1])\n",
    "\n",
    "    width_box2 = (box2[2] - box2[0])\n",
    "    height_box2 = (box2[3] - box2[1])\n",
    "\n",
    "    # area of box1 and box2\n",
    "    area_box1 = width_box1 * height_box1\n",
    "    area_box2 = width_box2 * height_box2\n",
    "\n",
    "    # union (including 2 * overlap area (double count))\n",
    "    area_union_overlap = area_box1 + area_box2\n",
    "\n",
    "    # union\n",
    "    area_union = area_union_overlap - area_overlap\n",
    "\n",
    "    # compute IOU\n",
    "    iou = area_overlap/ area_union\n",
    "\n",
    "    return iou\n",
    "\n",
    "def to_VOC_format(width, height, center_x, center_y):\n",
    "    \"\"\"\n",
    "    Convert center coordinate format to min max coordinateformat\n",
    "    \"\"\"\n",
    "    x_min = center_x - 0.5 * width\n",
    "    y_min = center_y - 0.5 * height\n",
    "    x_max = center_x + 0.5 * width\n",
    "    y_max = center_y + 0.5 * height\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "def to_center_format(xmin_list, ymin_list, xmax_list, ymax_list):\n",
    "    \"\"\"\n",
    "    Convert min max coordinate format to x_center, y_center, height and width format\n",
    "    \"\"\"\n",
    "    height = ymax_list - ymin_list\n",
    "    width = xmax_list - xmin_list\n",
    "\n",
    "    center_x = xmin_list + 0.5 * width\n",
    "    center_y = ymin_list + 0.5 * height\n",
    "\n",
    "    return width, height, center_x, center_y\n",
    "\n",
    "def adjust_deltas(anchor_width, anchor_height, anchor_center_x, anchor_center_y, dx, dy, dw, dh):\n",
    "    \"\"\"\n",
    "    Adjust the anchor box with predicted offset\n",
    "    \"\"\"\n",
    "    # ctr_x = dx * anc_width[:, np.newaxis] + anc_ctr_x[:, np.newaxis]\n",
    "    center_x = dx * anchor_width + anchor_center_x\n",
    "\n",
    "    # ctr_y = dy * anc_height[:, np.newaxis] + anc_ctr_y[:, np.newaxis]\n",
    "    center_y = dy *  anchor_height + anchor_center_y\n",
    "\n",
    "    # w = np.exp(dw) * anc_width[:, np.newaxis]\n",
    "    width = np.exp(dw) * anchor_width\n",
    "\n",
    "    # np.exp(dh) * anc_height[:, np.newaxis]\n",
    "    height = np.exp(dh) * anchor_height\n",
    "\n",
    "    return width, height, center_x, center_y\n",
    "\n",
    "stride = 8\n",
    "w = h = 800\n",
    "\n",
    "x_center = np.arange(3, w, stride) # [  0,  32,  64,  96, 128, 160, 192,...]\n",
    "y_center = np.arange(3, h, stride) # [  0,  32,  64,  96, 128, 160, 192,...]\n",
    "\n",
    "        # generate all the ordered pair of x and y center\n",
    "\n",
    "        # to achive this, we will use meshgrid and reshape it\n",
    "center_list = np.array(np.meshgrid(x_center, y_center,  sparse=False, indexing='xy')).T.reshape(-1,2)\n",
    "    ##########################################################\n",
    "\n",
    "    #al = []\n",
    "\n",
    "#anchor_shape = [(4,4),(6,6),(10,10),(16,16),(22,22),(32,32)]\n",
    "anchor_shape = [(8,8),(25,25),(38,38),(58,58),(85,85),(120,120)]\n",
    "n_anchors = len(center_list) * len(anchor_shape)\n",
    "\n",
    "\n",
    "anchor_list = np.zeros(shape= (n_anchors, 4))\n",
    "\n",
    "count = 0\n",
    "for center in center_list:\n",
    "         center_x, center_y = center[0], center[1]\n",
    "            # for each ratio\n",
    "         for w,h in anchor_shape:\n",
    "              # for each scale\n",
    "             anchor_xmin,anchor_ymin,anchor_xmax,anchor_ymax = to_VOC_format(w, h, center_x, center_y)\n",
    "             #al.append([center_x, center_y, w, h])\n",
    "                    # append the anchor box to anchor list\n",
    "             anchor_list[count] = [anchor_xmin, anchor_ymin, anchor_xmax, anchor_ymax]\n",
    "             count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e2eaaf4-8ad7-4394-a237-3ac0fd267145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_RoI(RPN, image_data, bbox_list1, anchor_list, u, th2):\n",
    "    # Initialize a list to store predicted RoIs\n",
    "    predict_roi = []\n",
    "\n",
    "    # Loop over each image in the batch\n",
    "    for i in range(image_data.shape[0]):\n",
    "        print(i)\n",
    "        img = image_data[i:i+1,:,:,:]\n",
    "        img = img.to(device)\n",
    "        \n",
    "        # Predict anchor deltas and objectness scores\n",
    "        anchor_deltas, objectiveness_score = model(img)\n",
    "        anchor_deltas = anchor_deltas.detach().numpy()\n",
    "        objectiveness_score = objectiveness_score.detach().numpy()\n",
    "        objectiveness_score = objectiveness_score.reshape(-1, n_anchors)\n",
    "        anchor_deltas = anchor_deltas.reshape(-1, n_anchors, 4)\n",
    "\n",
    "        # Extract deltas for adjustment\n",
    "        dx, dy, dw, dh = anchor_deltas[:, :, 0], anchor_deltas[:, :, 1], anchor_deltas[:, :, 2], anchor_deltas[:, :, 3]\n",
    "\n",
    "        # Convert anchor box coordinates to center format\n",
    "        anchor_width, anchor_height, anchor_center_x, anchor_center_y = to_center_format(\n",
    "            anchor_list[:, 0], anchor_list[:, 1], anchor_list[:, 2], anchor_list[:, 3])\n",
    "\n",
    "        # Adjust the anchors using the predicted deltas to obtain the final RoIs\n",
    "        roi_width, roi_height, roi_center_x, roi_center_y = adjust_deltas(\n",
    "            anchor_width, anchor_height, anchor_center_x, anchor_center_y, dx, dy, dw, dh)\n",
    "\n",
    "        # Convert RoIs back to VOC format\n",
    "        roi_min_x, roi_min_y, roi_max_x, roi_max_y = to_VOC_format(roi_width, roi_height, roi_center_x, roi_center_y)\n",
    "        roi = np.vstack((roi_min_x, roi_min_y, roi_max_x, roi_max_y)).T\n",
    "\n",
    "        # Filter out small and big RoIs based on size thresholds\n",
    "        min_size = 30\n",
    "        max_size = 160\n",
    "        width = roi[:, 2] - roi[:, 0]\n",
    "        height = roi[:, 3] - roi[:, 1]\n",
    "        keep = np.where((width >= min_size) & (height <= max_size) & (height >= min_size))[0]\n",
    "        roi = roi[keep]\n",
    "        score = objectiveness_score[:, keep]\n",
    "\n",
    "        # Sort RoIs by objectiveness score\n",
    "        sorted_idx = score.flatten().argsort()[::-1]\n",
    "        roi_sorted = roi[sorted_idx]\n",
    "        bbox_list = bbox_list1[i]\n",
    "\n",
    "        # Final filtering based on region content\n",
    "        imgg = np.reshape(img,(800,800,3))\n",
    "        img1 = imgg[:,:,1]\n",
    "        indd = []\n",
    "        for ii in range(len(roi_sorted)):\n",
    "            bbox_list11 = roi_sorted[ii]\n",
    "            anchor_width1, anchor_height1, anchor_center_x1, anchor_center_y1 = to_center_format(\n",
    "                bbox_list11[0], bbox_list11[1], bbox_list11[2], bbox_list11[3])\n",
    "            \n",
    "            img2 = img1[np.int64(anchor_center_x1-anchor_width1/2):np.int64(anchor_center_x1+anchor_height1/2),\n",
    "                        np.int64(anchor_center_y1-anchor_width1/2):np.int64(anchor_center_y1+anchor_height1/2)]\n",
    "\n",
    "            if (img2.shape[0]) > 0:\n",
    "                indd.append(ii)\n",
    "                if len(indd) >= th2:\n",
    "                    break\n",
    "\n",
    "        roi_sorted = roi_sorted[indd, :]\n",
    "        predict_roi.append(roi_sorted)\n",
    "      \n",
    "    return predict_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62e2ba09-673f-43b5-82ad-3428d91402da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_21652\\51013407.py:88: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(ww+\".pth\", map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomRPN(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv8): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv10): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv11): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (deconv1): ConvTranspose2d(512, 512, kernel_size=(1, 1), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (conv15): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
       "  (conv16): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv17): Conv2d(512, 510, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (regressor): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (classifier): Conv2d(512, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Define the CustomRPN class inheriting from nn.Module\n",
    "class CustomRPN(nn.Module):\n",
    "    def __init__(self, k=6, weight_decay=0.000001):\n",
    "        super(CustomRPN, self).__init__()\n",
    "\n",
    "        # Define the first set of convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Pooling layer for downsampling\n",
    "\n",
    "        # Define the second set of convolutional layers\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        # Continue adding more convolutional layers for deeper feature extraction\n",
    "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.conv8 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv9 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv10 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Define additional convolutional layers\n",
    "        self.conv11 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv13 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Define a transposed convolutional layer for upsampling\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=1, stride=2, padding=1, output_padding=1)\n",
    "\n",
    "        # Define final convolutional layers for bounding box regression and classification\n",
    "        self.conv15 = nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, padding=1)\n",
    "        self.conv16 = nn.Conv2d(in_channels=256, out_channels=1, kernel_size=1)\n",
    "        self.conv17 = nn.Conv2d(in_channels=512, out_channels=510, kernel_size=1)\n",
    "\n",
    "        # Regressor for bounding box prediction and classifier for objectness score\n",
    "        self.regressor = nn.Conv2d(in_channels=512, out_channels=4*k, kernel_size=1)\n",
    "        self.classifier = nn.Conv2d(in_channels=512, out_channels=k, kernel_size=1)\n",
    "\n",
    "    # Forward pass through the network\n",
    "    def forward(self, x):\n",
    "        x1 = F.relu(self.conv1(x))  # First convolutional block\n",
    "        x2 = F.relu(self.conv2(x1))\n",
    "        p1 = self.pool(x2)\n",
    "        \n",
    "        x3 = F.relu(self.conv3(p1))  # Second convolutional block\n",
    "        x4 = F.relu(self.conv4(x3))\n",
    "        p2 = self.pool(x4)\n",
    "        \n",
    "        x5 = F.relu(self.conv5(p2))  # Third convolutional block\n",
    "        x6 = F.relu(self.conv6(x5))\n",
    "        x7 = F.relu(self.conv7(x6))\n",
    "        p3 = self.pool(x7)\n",
    "        \n",
    "        x8 = F.relu(self.conv8(p3))  # Fourth convolutional block\n",
    "        x9 = F.relu(self.conv9(x8))\n",
    "        x10 = F.relu(self.conv10(x9))\n",
    "        p4 = self.pool(x10)\n",
    "        \n",
    "        x11 = F.relu(self.conv11(p4))  # Fifth convolutional block\n",
    "        x12 = F.relu(self.conv12(x11))\n",
    "        x13 = F.relu(self.conv13(x12))\n",
    "        \n",
    "        x14 = self.deconv1(x13)  # Upsampling with transposed convolution\n",
    "        x15 = self.conv15(x14)\n",
    "\n",
    "        # Additional convolutions for feature maps at different stages\n",
    "        x18 = self.conv16(p3)\n",
    "        x19 = self.conv17(x10)\n",
    "        \n",
    "        # Concatenate feature maps from different layers\n",
    "        concatenated = torch.cat([x15, x19, x18], dim=1)\n",
    "        \n",
    "        # Predict bounding boxes (regressor) and objectness score (classifier)\n",
    "        regressor = self.regressor(concatenated)\n",
    "        classifier = torch.sigmoid(self.classifier(concatenated))\n",
    "\n",
    "        return regressor, classifier\n",
    "\n",
    "# Load the entire model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CustomRPN()\n",
    "# Load the saved model weights\n",
    "ww = 'RPN_torch'\n",
    "model = torch.load(ww+\".pth\", map_location=torch.device('cpu'))\n",
    "model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c1b37e-c1ff-4459-953b-849e0ad903d6",
   "metadata": {},
   "source": [
    "The goal of this code is to extract and classify image regions from a dataset based on predicted regions of interest (RoIs) from a model. It processes each image by cropping and resizing areas defined by bounding boxes and RoIs, categorizing them into positive or negative examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003225e-a223-4abf-b031-571e3d577f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all data from images tensor\n",
    "image_data2 = images[:, :, :, :]\n",
    "number, _, _, _ = image_data2.shape  # Extract the number of images\n",
    "\n",
    "th2 = 100  # Set threshold value for number of RoIs to process\n",
    "# Get sorted RoIs based on the model's output\n",
    "roi_sorted1 = Get_RoI(model, image_data2, bbox_list1, anchor_list, u, th2)\n",
    "\n",
    "image_fpr = []  # Initialize list to store region images\n",
    "label = []  # Initialize list to store labels for images\n",
    "k = 0  # Counter for number of processed images\n",
    "\n",
    "# Loop through each image\n",
    "for i in range(number):\n",
    "    print(i)  # Print the current image index\n",
    "    img = Data['images'][i, :, :, 1]  # Extract image for the current index\n",
    "    bbox = bbox_list1[i, :]  # Extract bounding box for the current index\n",
    "    \n",
    "    # Crop image based on bounding box and resize\n",
    "    img2 = img[np.int64(bbox[0]):np.int64(bbox[2]), np.int64(bbox[1]):np.int64(bbox[3])]\n",
    "    img3 = cv2.resize(img2, dsize=(60, 60), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Append resized image and label to lists\n",
    "    image_fpr.append(img3)\n",
    "    label.append(1)  # Label 1 for positive examples\n",
    "    k += 1  # Increment counter for processed images\n",
    "    num_count = 0  # Counter for number of negative samples added\n",
    "    \n",
    "    # Process RoIs to identify potential false positives\n",
    "    roi_sorted = roi_sorted1[i]\n",
    "    for k1 in range(th2):\n",
    "        iou1 = IOU(bbox, roi_sorted[k1])  # Compute Intersection over Union (IoU)\n",
    "        bbox0 = roi_sorted[k1]\n",
    "        dia1 = bbox0[2] - bbox0[0]  # Width of bounding box\n",
    "        dia2 = bbox0[3] - bbox0[1]  # Height of bounding box\n",
    "        dia_min = min([dia1, dia2])  # Minimum dimension\n",
    "        dia_max = max([dia1, dia2])  # Maximum dimension\n",
    "\n",
    "        # Check conditions for adding negative samples\n",
    "        if (iou1 == 0) & (dia_min > 10) & (dia_max < 120):\n",
    "            img2 = img[np.int64(bbox0[0]):np.int64(bbox0[2]), np.int64(bbox0[1]):np.int64(bbox0[3])]\n",
    "            img3 = cv2.resize(img2, dsize=(60, 60), interpolation=cv2.INTER_CUBIC)\n",
    "            \n",
    "            if np.mean(img3) != 0:  # Ensure non-empty image\n",
    "                label.append(0)  # Label 0 for negative examples\n",
    "                image_fpr.append(img3)\n",
    "                k += 1\n",
    "                num_count += 1\n",
    "                \n",
    "            if num_count == 3:  # Stop after collecting 3 negative samples\n",
    "                break\n",
    "\n",
    "    # Add additional positive samples with high IoU\n",
    "    count = 0\n",
    "    for k1 in range(th2):\n",
    "        iou1 = IOU(bbox, roi_sorted[k1])  # Compute Intersection over Union (IoU)\n",
    "        bbox0 = roi_sorted[k1]\n",
    "        if (iou1 > 0.7) & (count < 2):\n",
    "            img2 = img[np.int64(bbox0[0]):np.int64(bbox0[2]), np.int64(bbox0[1]):np.int64(bbox0[3])]\n",
    "            img3 = cv2.resize(img2, dsize=(60, 60), interpolation=cv2.INTER_CUBIC)\n",
    "            image_fpr.append(img3)\n",
    "            label.append(1)  # Label 1 for positive examples\n",
    "            k += 1\n",
    "            count += 1\n",
    "\n",
    "# Save images and labels to pickle files\n",
    "data = {'output': image_fpr}\n",
    "with open('Image_LUNG.pkl', 'wb') as file:\n",
    "    pickle.dump(data, file)\n",
    "\n",
    "label = {'output': label}\n",
    "with open('label_LUNG.pkl', 'wb') as file:\n",
    "    pickle.dump(label, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34704080-b01b-4764-b74e-4a22b277bca0",
   "metadata": {},
   "source": [
    "This code loads image and label data from pickle files, retrieves a specific image and its label using a predefined index (Num_image), and displays the selected image using Matplotlib. It sets the plot title to \"Nodule\" if the label indicates the presence of a nodule (1), or \"Non-Nodule\" if the label indicates its absence (0). The image is shown in grayscale, providing a visual representation of the data along with a descriptive title based on its label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51beb3b4-c441-40b0-a304-6700fa115eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the image data from a pickle file\n",
    "with open('Image_LUNG.pkl', 'rb') as f:\n",
    "   image = pickle.load(f)  # Load the dictionary containing image data\n",
    "\n",
    "# Load the label data from a pickle file\n",
    "with open('label_LUNG.pkl', 'rb') as f:\n",
    "   label1 = pickle.load(f)  # Load the dictionary containing label data\n",
    "\n",
    "Num_image = 8  # Set the index of the image to be displayed\n",
    "\n",
    "# Extract the selected image using the index\n",
    "img_test = image['output'][Num_image]\n",
    "\n",
    "# Create a figure and axes for plotting\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Display the selected image in grayscale\n",
    "plt.imshow(img_test, cmap='gray')\n",
    "\n",
    "# Set the title of the plot based on the label of the selected image\n",
    "if label1['output'][Num_image] == 1:\n",
    "    ax.set_title('Nodule')  # Title for positive examples\n",
    "else:\n",
    "    ax.set_title('Non-Nodule')  # Title for negative examples\n",
    "\n",
    "# Show the plot with the image and title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eea1d2-f7ae-49fd-8463-7ab91f14e024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
